{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook:\n",
    "\n",
    "# utilize TFIDF to create sparse word vector\n",
    "# conduct sentiment analysis on Amazon game reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import pivot_table\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 98144 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helppercent</th>\n",
       "      <th>overall</th>\n",
       "      <th>cleansum</th>\n",
       "      <th>cleantxt</th>\n",
       "      <th>cleanboth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>pay unlock content dont think</td>\n",
       "      <td>installing game struggle games windows live ch...</td>\n",
       "      <td>pay unlock content dont think installing game ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3</td>\n",
       "      <td>awesome game crash frequently</td>\n",
       "      <td>got version instead ps version turned mistake ...</td>\n",
       "      <td>awesome game crash frequently got version inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>dirt</td>\n",
       "      <td>dirt xbox okay game started playing games lapt...</td>\n",
       "      <td>dirt dirt xbox okay game started playing games...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5</td>\n",
       "      <td>step dirt terrific</td>\n",
       "      <td>loved playing dirt thought graphics good purch...</td>\n",
       "      <td>step dirt terrific loved playing dirt thought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>couldnt get one work</td>\n",
       "      <td>still havent figured one everything instructed...</td>\n",
       "      <td>couldnt get one work still havent figured one ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  helppercent  overall                       cleansum  \\\n",
       "0  0700099867     0.666667        1  pay unlock content dont think   \n",
       "1  0700099867     0.700000        3  awesome game crash frequently   \n",
       "2  0700099867     1.000000        4                           dirt   \n",
       "3  0700099867     0.846154        5             step dirt terrific   \n",
       "4  0700099867     1.000000        2           couldnt get one work   \n",
       "\n",
       "                                            cleantxt  \\\n",
       "0  installing game struggle games windows live ch...   \n",
       "1  got version instead ps version turned mistake ...   \n",
       "2  dirt xbox okay game started playing games lapt...   \n",
       "3  loved playing dirt thought graphics good purch...   \n",
       "4  still havent figured one everything instructed...   \n",
       "\n",
       "                                           cleanboth  \n",
       "0  pay unlock content dont think installing game ...  \n",
       "1  awesome game crash frequently got version inst...  \n",
       "2  dirt dirt xbox okay game started playing games...  \n",
       "3  step dirt terrific loved playing dirt thought ...  \n",
       "4  couldnt get one work still havent figured one ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gedit = pd.read_csv('amazon_games_clean.csv',index_col=0)\n",
    "\n",
    "print(f'Dataset has {gedit.shape[0]} samples')\n",
    "\n",
    "gedit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10441 unique games\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(gedit['asin'].unique())} unique games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0700099867\n",
      "6050036071\n",
      "7100027950\n",
      "7293000936\n",
      "8176503290\n",
      "907843905X\n",
      "9625990674\n",
      "9861019731\n",
      "9882155456\n",
      "B000003SQQ\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(gedit['asin'].unique()[i])\n",
    "# brief look at the unique identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique games with 20+ reviews: 1044\n"
     ]
    }
   ],
   "source": [
    "vc_asin = gedit['asin'].value_counts()\n",
    "vc_asin = vc_asin[vc_asin >= 20]\n",
    "\n",
    "print(f'Unique games with 20+ reviews: {len(vc_asin)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size of 20+ reviews games: 42471\n",
      "Dataset unique word size is: 63464\n"
     ]
    }
   ],
   "source": [
    "# removing games with less than 20 reviews\n",
    "# this is to keep the word vectors manageable\n",
    "gedit = gedit[gedit['asin'].isin(list(vc_asin.index))]\n",
    "\n",
    "print(f'Dataset size of 20+ reviews games: {gedit.shape[0]}')\n",
    "print(f\"Dataset unique word size is: {len(pd.Series(' '.join(gedit['cleanboth']).split()).value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<42471x63255 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4473159 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(max_features=80000, lowercase=True, analyzer='word',\n",
    "                        stop_words = 'english', ngram_range=(1,1))\n",
    "\n",
    "tfvec = tf.fit_transform(gedit['cleanboth'])\n",
    "\n",
    "tfvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (31853, 63255)\n",
      "y_train: (31853,)\n",
      "x_test: (10618, 63255)\n",
      "y_test: (10618,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, x_test, y_train, y_test) = train_test_split(tfvec, gedit['overall'], test_size=0.25)\n",
    "\n",
    "print(f'x_train: {x_train.shape}\\ny_train: {y_train.shape}')\n",
    "print(f'x_test: {x_test.shape}\\ny_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: C=0.01 0.5550009417969486\n",
      "Logistic Regression Accuracy: C=0.25 0.6166886419288001\n",
      "Logistic Regression Accuracy: C=0.5 0.6343002448672066\n",
      "Logistic Regression Accuracy: C=1.0 0.6465436051987191\n",
      "Logistic Regression Accuracy: C=1.5 0.6507816914673197\n",
      "Logistic Regression Accuracy: C=2.0 0.6505933320776041\n",
      "Logistic Regression Accuracy: C=5.0 0.6451309097758523\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.25, 0.5, 1.0, 1.5, 2.0, 5.0]:\n",
    "    \n",
    "    lreg = LogisticRegression(C=c)\n",
    "    lreg.fit(x_train, y_train)\n",
    "    print (f'Logistic Regression Accuracy: C={c} {accuracy_score(y_test, lreg.predict(x_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.5557543793558108\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb = mnb.fit(x_train, y_train)\n",
    "\n",
    "print (f'Naive Bayes Accuracy: {accuracy_score(y_test, mnb.predict(x_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = ['There are no words to describe the experience that is Zelda Ocerina of Time, simply amazing!',\n",
    "               'Zombicide is an unpolished piece of crap made to cheat fans out of their money',\n",
    "               'Rampage is a cheesy game with some great gems in it',\n",
    "               'This game is so so so good, will play again!',\n",
    "               'Do not waste your money on this trash heap',\n",
    "               'Some fun levels, but UI is pretty clunky and video angle is terrible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def clean_test_phrase(x):\n",
    "    x = x.lower()\n",
    "    new_str = ''\n",
    "    for c in x:\n",
    "        if (c.isalpha() == True) or (c == ' '):\n",
    "            new_str += c\n",
    "    new_str = \" \".join(w for w in str(new_str).split() if w not in stop)\n",
    "                       \n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['words describe experience zelda ocerina time simply amazing', 'zombicide unpolished piece crap made cheat fans money', 'rampage cheesy game great gems', 'game good play', 'waste money trash heap', 'fun levels ui pretty clunky video angle terrible']\n"
     ]
    }
   ],
   "source": [
    "test_clean = []\n",
    "\n",
    "for i in test_phrase:\n",
    "    test_clean.append(clean_test_phrase(i))\n",
    "print(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x63255 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec = tf.transform(test_clean)\n",
    "\n",
    "test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression prediction: 5  There are no words to describe the experience that is Zelda Ocerina of Time, simply amazing!\n",
      "Logistic regression prediction: 1  Zombicide is an unpolished piece of crap made to cheat fans out of their money\n",
      "Logistic regression prediction: 5  Rampage is a cheesy game with some great gems in it\n",
      "Logistic regression prediction: 4  This game is so so so good, will play again!\n",
      "Logistic regression prediction: 1  Do not waste your money on this trash heap\n",
      "Logistic regression prediction: 3  Some fun levels, but UI is pretty clunky and video angle is terrible\n"
     ]
    }
   ],
   "source": [
    "# we see pretty good prediction with lreg\n",
    "lreg = LogisticRegression(C=1.5)\n",
    "lreg = lreg.fit(x_train, y_train)\n",
    "test_lreg = lreg.predict(test_vec)\n",
    "\n",
    "for phrase, pred in zip(test_phrase, test_lreg):\n",
    "    print(f'Logistic regression prediction: {pred}  {phrase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes prediction: 5  There are no words to describe the experience that is Zelda Ocerina of Time, simply amazing!\n",
      "Naive Bayes prediction: 5  Zombicide is an unpolished piece of crap made to cheat fans out of their money\n",
      "Naive Bayes prediction: 5  Rampage is a cheesy game with some great gems in it\n",
      "Naive Bayes prediction: 5  This game is so so so good, will play again!\n",
      "Naive Bayes prediction: 5  Do not waste your money on this trash heap\n",
      "Naive Bayes prediction: 5  Some fun levels, but UI is pretty clunky and video angle is terrible\n"
     ]
    }
   ],
   "source": [
    "# we see ineffective prediction with Naive Bayes\n",
    "test_mnb = mnb.predict(test_vec)\n",
    "\n",
    "for phrase, pred in zip(test_phrase, test_mnb):\n",
    "    print(f'Naive Bayes prediction: {pred}  {phrase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    23593\n",
       "4     9204\n",
       "3     4727\n",
       "1     2659\n",
       "2     2288\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes' mispredictions may be influenced by '5' representing >50% of the ratings\n",
    "# Naive Bayes is a probabilistic regression\n",
    "gedit['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this concludes pt 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
