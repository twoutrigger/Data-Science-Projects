{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook:\n",
    "\n",
    "# utilize TFIDF to create sparse word vector\n",
    "# conduct sentiment analysis on Amazon game reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 98144 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helppercent</th>\n",
       "      <th>overall</th>\n",
       "      <th>cleansum</th>\n",
       "      <th>cleantxt</th>\n",
       "      <th>cleanboth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>pay unlock content dont think</td>\n",
       "      <td>instal game wa struggle game window live champ...</td>\n",
       "      <td>pay unlock content dont think instal game wa s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3</td>\n",
       "      <td>awesome game crash frequently</td>\n",
       "      <td>get version instead p version turn mistake con...</td>\n",
       "      <td>awesome game crash frequently get version inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>dirt</td>\n",
       "      <td>dirt xbox wa okay game start play game laptop ...</td>\n",
       "      <td>dirt dirt xbox wa okay game start play game la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>5</td>\n",
       "      <td>step dirt terrific</td>\n",
       "      <td>love play dirt think graphic good purchase dir...</td>\n",
       "      <td>step dirt terrific love play dirt think graphi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>couldnt get one work</td>\n",
       "      <td>still havent figure one everything instruct ga...</td>\n",
       "      <td>couldnt get one work still havent figure one e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  helppercent  overall                       cleansum  \\\n",
       "0  0700099867     0.666667        1  pay unlock content dont think   \n",
       "1  0700099867     0.700000        3  awesome game crash frequently   \n",
       "2  0700099867     1.000000        4                           dirt   \n",
       "3  0700099867     0.846154        5             step dirt terrific   \n",
       "4  0700099867     1.000000        2           couldnt get one work   \n",
       "\n",
       "                                            cleantxt  \\\n",
       "0  instal game wa struggle game window live champ...   \n",
       "1  get version instead p version turn mistake con...   \n",
       "2  dirt xbox wa okay game start play game laptop ...   \n",
       "3  love play dirt think graphic good purchase dir...   \n",
       "4  still havent figure one everything instruct ga...   \n",
       "\n",
       "                                           cleanboth  \n",
       "0  pay unlock content dont think instal game wa s...  \n",
       "1  awesome game crash frequently get version inst...  \n",
       "2  dirt dirt xbox wa okay game start play game la...  \n",
       "3  step dirt terrific love play dirt think graphi...  \n",
       "4  couldnt get one work still havent figure one e...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gedit = pd.read_csv('amazon_games_clean.csv',index_col=0)\n",
    "\n",
    "print(f'Dataset has {gedit.shape[0]} samples')\n",
    "\n",
    "gedit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10441 unique games\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(gedit['asin'].unique())} unique games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0700099867\n",
      "6050036071\n",
      "7100027950\n",
      "7293000936\n",
      "8176503290\n",
      "907843905X\n",
      "9625990674\n",
      "9861019731\n",
      "9882155456\n",
      "B000003SQQ\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(gedit['asin'].unique()[i])\n",
    "# brief look at the unique identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique games with 20+ reviews: 1044\n"
     ]
    }
   ],
   "source": [
    "vc_asin = gedit['asin'].value_counts()\n",
    "vc_asin = vc_asin[vc_asin >= 20]\n",
    "\n",
    "print(f'Unique games with 20+ reviews: {len(vc_asin)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size of 20+ reviews games: 42471\n",
      "Dataset unique word size is: 51116\n"
     ]
    }
   ],
   "source": [
    "# removing games with less than 20 reviews\n",
    "# this is to keep the word vectors manageable\n",
    "gedit = gedit[gedit['asin'].isin(list(vc_asin.index))]\n",
    "\n",
    "print(f'Dataset size of 20+ reviews games: {gedit.shape[0]}')\n",
    "print(f\"Dataset unique word size is: {len(pd.Series(' '.join(gedit['cleanboth']).split()).value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<42471x50916 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4119042 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(max_features=80000, lowercase=True, analyzer='word',\n",
    "                        stop_words = 'english', ngram_range=(1,1))\n",
    "\n",
    "tfvec = tf.fit_transform(gedit['cleanboth'])\n",
    "\n",
    "tfvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (31853, 50916)\n",
      "y_train: (31853,)\n",
      "x_test: (10618, 50916)\n",
      "y_test: (10618,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, x_test, y_train, y_test) = train_test_split(tfvec, gedit['overall'], test_size=0.25)\n",
    "\n",
    "print(f'x_train: {x_train.shape}\\ny_train: {y_train.shape}')\n",
    "print(f'x_test: {x_test.shape}\\ny_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: C=0.01 0.5482200037671878\n",
      "Logistic Regression Accuracy: C=0.5 0.6354304012055001\n",
      "Logistic Regression Accuracy: C=1.0 0.6486155584855905\n",
      "Logistic Regression Accuracy: C=2.0 0.6540779807873423\n",
      "Logistic Regression Accuracy: C=4.0 0.6507816914673197\n",
      "Logistic Regression Accuracy: C=5.0 0.6499340742135995\n",
      "Logistic Regression Accuracy: C=7.5 0.6459785270295724\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.5, 1.0, 2.0, 4.0, 5.0, 7.5]:\n",
    "    \n",
    "    lreg = LogisticRegression(C=c)\n",
    "    lreg.fit(x_train, y_train)\n",
    "    print (f'Logistic Regression Accuracy: C={c} {accuracy_score(y_test, lreg.predict(x_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.5489734413260501\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb = mnb.fit(x_train, y_train)\n",
    "\n",
    "print (f'Naive Bayes Accuracy: {accuracy_score(y_test, mnb.predict(x_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = ['There are no words to describe the experience that is Zelda Ocerina of Time, simply amazing!',\n",
    "               'Zombicide is an unpolished piece of crap made to cheat fans out of their money',\n",
    "               'Rampage is a cheesy game with some great gems in it',\n",
    "               'This game is so so so good, will play again!',\n",
    "               'Do not waste your money on this trash heap',\n",
    "               'Some nice levels, but UI is pretty clunky and video angle is terrible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def clean_test_phrase(x):\n",
    "    x = x.lower()\n",
    "    new_str = ''\n",
    "    for c in x:\n",
    "        if (c.isalpha() == True) or (c == ' '):\n",
    "            new_str += c\n",
    "    new_str = \" \".join(Word(w).lemmatize() for w in str(new_str).split())\n",
    "    new_str = \" \".join(Word(w).lemmatize(pos='v') for w in str(new_str).split())\n",
    "    new_str = \" \".join(w for w in str(new_str).split() if w not in stop)\n",
    "                       \n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word describe experience zelda ocerina time simply amaze', 'zombicide unpolished piece crap make cheat fan money', 'rampage cheesy game great gem', 'game good play', 'waste money trash heap', 'nice level ui pretty clunky video angle terrible']\n"
     ]
    }
   ],
   "source": [
    "test_clean = []\n",
    "\n",
    "for i in test_phrase:\n",
    "    test_clean.append(clean_test_phrase(i))\n",
    "print(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x50916 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 33 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec = tf.transform(test_clean)\n",
    "\n",
    "test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression prediction: 5  There are no words to describe the experience that is Zelda Ocerina of Time, simply amazing!\n",
      "Logistic regression prediction: 1  Zombicide is an unpolished piece of crap made to cheat fans out of their money\n",
      "Logistic regression prediction: 5  Rampage is a cheesy game with some great gems in it\n",
      "Logistic regression prediction: 4  This game is so so so good, will play again!\n",
      "Logistic regression prediction: 1  Do not waste your money on this trash heap\n",
      "Logistic regression prediction: 2  Some nice levels, but UI is pretty clunky and video angle is terrible\n"
     ]
    }
   ],
   "source": [
    "# we see pretty good prediction with lreg\n",
    "lreg = LogisticRegression(C=2)\n",
    "lreg = lreg.fit(x_train, y_train)\n",
    "test_lreg = lreg.predict(test_vec)\n",
    "\n",
    "for phrase, pred in zip(test_phrase, test_lreg):\n",
    "    print(f'Logistic regression prediction: {pred}  {phrase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes prediction: 5  There are no words to describe the experience that is Zelda Ocerina of Time, simply amazing!\n",
      "Naive Bayes prediction: 5  Zombicide is an unpolished piece of crap made to cheat fans out of their money\n",
      "Naive Bayes prediction: 5  Rampage is a cheesy game with some great gems in it\n",
      "Naive Bayes prediction: 5  This game is so so so good, will play again!\n",
      "Naive Bayes prediction: 5  Do not waste your money on this trash heap\n",
      "Naive Bayes prediction: 5  Some nice levels, but UI is pretty clunky and video angle is terrible\n"
     ]
    }
   ],
   "source": [
    "# we see ineffective prediction with Naive Bayes\n",
    "test_mnb = mnb.predict(test_vec)\n",
    "\n",
    "for phrase, pred in zip(test_phrase, test_mnb):\n",
    "    print(f'Naive Bayes prediction: {pred}  {phrase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    23593\n",
       "4     9204\n",
       "3     4727\n",
       "1     2659\n",
       "2     2288\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes' mispredictions may be influenced by '5' representing >50% of the ratings\n",
    "# Naive Bayes is a probabilistic regression\n",
    "gedit['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this concludes pt 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
