{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20323905",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic image classification algo using CNN\n",
    "## tutorial url\n",
    "## https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6277458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.utils import load_img # moved from .preprocessing.image\n",
    "from keras.utils import img_to_array # moved from .preprocessing.image\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define location of dataset\n",
    "folder = '../../../Large_Datasets/cat_dog_train/'\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# define filename\n",
    "\tfilename = folder + 'dog.' + str(i) + '.jpg'\n",
    "\t# load image pixels\n",
    "\timage = imread(filename)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092ab92",
   "metadata": {},
   "source": [
    "#### Pre-process image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the standard directories approach instead\n",
    "# folder = '../../../Large_Datasets/cat_dog_train/'\n",
    "# photos, labels = list(), list()\n",
    "# # enumerate files in the directory\n",
    "# for file in listdir(folder):\n",
    "# \t# determine class\n",
    "# \toutput = 0.0\n",
    "# \tif file.startswith('dog'):\n",
    "# \t\toutput = 1.0\n",
    "# \t# load image\n",
    "# \tphoto = load_img(folder + file, target_size=(200, 200))\n",
    "# \t# convert to numpy array\n",
    "# \tphoto = img_to_array(photo)\n",
    "# \t# store\n",
    "# \tphotos.append(photo)\n",
    "# \tlabels.append(output)\n",
    "# # convert to a numpy arrays\n",
    "# photos = asarray(photos)\n",
    "# labels = asarray(labels)\n",
    "# print(photos.shape, labels.shape)\n",
    "# # save the reshaped photos\n",
    "# save('dogs_vs_cats_photos.npy', photos)\n",
    "# save('dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the standard directories approach instead\n",
    "# photos = load('dogs_vs_cats_photos.npy')\n",
    "# labels = load('dogs_vs_cats_labels.npy')\n",
    "# print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693dd59",
   "metadata": {},
   "source": [
    "#### Pre-Process Photos into Standard Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard directory created successfully\n",
    "# dataset_home = '../../../Large_Datasets/dataset_dogs_vs_cats/'\n",
    "# subdirs = ['train/', 'test/']\n",
    "# for subdir in subdirs:\n",
    "# \t# create label subdirectories\n",
    "# \tlabeldirs = ['dogs/', 'cats/']\n",
    "# \tfor labldir in labeldirs:\n",
    "# \t\tnewdir = dataset_home + subdir + labldir\n",
    "# \t\tmakedirs(newdir, exist_ok=True)\n",
    "# # seed random number generator\n",
    "# seed(1)\n",
    "# # define ratio of pictures to use for validation\n",
    "# val_ratio = 0.25\n",
    "# # copy training dataset images into subdirectories\n",
    "# # src_directory = 'train/'\n",
    "# src_directory = '../../../Large_Datasets/cat_dog_train'\n",
    "# for file in listdir(src_directory):\n",
    "# \tsrc = src_directory + '/' + file\n",
    "# \tdst_dir = 'train/'\n",
    "# \tif random() < val_ratio:\n",
    "# \t\tdst_dir = 'test/'\n",
    "# \tif file.startswith('cat'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
    "# \t\tcopyfile(src, dst)\n",
    "# \telif file.startswith('dog'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "# \t\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2774f3b",
   "metadata": {},
   "source": [
    "#### Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357f8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa218c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6de42ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## need to investigate\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673df3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## need to investigate\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f37df5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18697 images belonging to 2 classes.\n",
      "Found 6303 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "293/293 [==============================] - 263s 898ms/step - loss: 0.7012 - accuracy: 0.5701 - val_loss: 0.6953 - val_accuracy: 0.5269\n",
      "Epoch 2/20\n",
      "293/293 [==============================] - 262s 894ms/step - loss: 0.6517 - accuracy: 0.6072 - val_loss: 0.6527 - val_accuracy: 0.6056\n",
      "Epoch 3/20\n",
      "293/293 [==============================] - 250s 853ms/step - loss: 0.6269 - accuracy: 0.6413 - val_loss: 0.6194 - val_accuracy: 0.6381\n",
      "Epoch 4/20\n",
      "293/293 [==============================] - 257s 876ms/step - loss: 0.6269 - accuracy: 0.6383 - val_loss: 0.6276 - val_accuracy: 0.6310\n",
      "Epoch 5/20\n",
      "293/293 [==============================] - 261s 890ms/step - loss: 0.6021 - accuracy: 0.6644 - val_loss: 0.6268 - val_accuracy: 0.6292\n",
      "Epoch 6/20\n",
      "293/293 [==============================] - 266s 908ms/step - loss: 0.5929 - accuracy: 0.6690 - val_loss: 0.6076 - val_accuracy: 0.6595\n",
      "Epoch 7/20\n",
      "293/293 [==============================] - 252s 860ms/step - loss: 0.5763 - accuracy: 0.6836 - val_loss: 0.5839 - val_accuracy: 0.6798\n",
      "Epoch 8/20\n",
      "293/293 [==============================] - 252s 859ms/step - loss: 0.5512 - accuracy: 0.7116 - val_loss: 0.5939 - val_accuracy: 0.6736\n",
      "Epoch 9/20\n",
      "293/293 [==============================] - 255s 870ms/step - loss: 0.5295 - accuracy: 0.7300 - val_loss: 0.5672 - val_accuracy: 0.6989\n",
      "Epoch 10/20\n",
      "293/293 [==============================] - 255s 870ms/step - loss: 0.5007 - accuracy: 0.7562 - val_loss: 0.5593 - val_accuracy: 0.7086\n",
      "Epoch 11/20\n",
      "293/293 [==============================] - 252s 858ms/step - loss: 0.4806 - accuracy: 0.7688 - val_loss: 0.5558 - val_accuracy: 0.7157\n",
      "Epoch 12/20\n",
      "293/293 [==============================] - 251s 856ms/step - loss: 0.4485 - accuracy: 0.7927 - val_loss: 0.5575 - val_accuracy: 0.7212\n",
      "Epoch 13/20\n",
      "293/293 [==============================] - 252s 860ms/step - loss: 0.4118 - accuracy: 0.8154 - val_loss: 0.5450 - val_accuracy: 0.7276\n",
      "Epoch 14/20\n",
      "293/293 [==============================] - 250s 854ms/step - loss: 0.3732 - accuracy: 0.8374 - val_loss: 0.6312 - val_accuracy: 0.6873\n",
      "Epoch 15/20\n",
      "293/293 [==============================] - 251s 858ms/step - loss: 0.3393 - accuracy: 0.8578 - val_loss: 0.5627 - val_accuracy: 0.7309\n",
      "Epoch 16/20\n",
      "293/293 [==============================] - 252s 860ms/step - loss: 0.2954 - accuracy: 0.8830 - val_loss: 0.5538 - val_accuracy: 0.7389\n",
      "Epoch 17/20\n",
      "293/293 [==============================] - 250s 854ms/step - loss: 0.2621 - accuracy: 0.9005 - val_loss: 0.5569 - val_accuracy: 0.7411\n",
      "Epoch 18/20\n",
      "293/293 [==============================] - 250s 854ms/step - loss: 0.2326 - accuracy: 0.9154 - val_loss: 0.6354 - val_accuracy: 0.7205\n",
      "Epoch 19/20\n",
      "293/293 [==============================] - 251s 856ms/step - loss: 0.2077 - accuracy: 0.9244 - val_loss: 0.6826 - val_accuracy: 0.7155\n",
      "Epoch 20/20\n",
      "293/293 [==============================] - 251s 857ms/step - loss: 0.1639 - accuracy: 0.9488 - val_loss: 0.7345 - val_accuracy: 0.7119\n",
      "WARNING:tensorflow:From C:\\Users\\liamk\\AppData\\Local\\Temp\\ipykernel_12032\\2204847392.py:46: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "> 71.188\n"
     ]
    }
   ],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterators\n",
    "    train_it = datagen.flow_from_directory('../../../Large_Datasets/dataset_dogs_vs_cats/train/',\n",
    "        class_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "    test_it = datagen.flow_from_directory('../../../Large_Datasets/dataset_dogs_vs_cats/test/',\n",
    "        class_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "    # fit model\n",
    "    history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    "    \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d750d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
