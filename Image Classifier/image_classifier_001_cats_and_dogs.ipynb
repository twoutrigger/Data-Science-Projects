{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20323905",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic image classification algo using CNN\n",
    "## tutorial url\n",
    "## https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6277458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.utils import load_img # moved from .preprocessing.image\n",
    "from keras.utils import img_to_array # moved from .preprocessing.image\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define location of dataset\n",
    "folder = '../../../Large_Datasets/cat_dog_train/'\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# define filename\n",
    "\tfilename = folder + 'dog.' + str(i) + '.jpg'\n",
    "\t# load image pixels\n",
    "\timage = imread(filename)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092ab92",
   "metadata": {},
   "source": [
    "#### Pre-process image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the standard directories approach instead\n",
    "# folder = '../../../Large_Datasets/cat_dog_train/'\n",
    "# photos, labels = list(), list()\n",
    "# # enumerate files in the directory\n",
    "# for file in listdir(folder):\n",
    "# \t# determine class\n",
    "# \toutput = 0.0\n",
    "# \tif file.startswith('dog'):\n",
    "# \t\toutput = 1.0\n",
    "# \t# load image\n",
    "# \tphoto = load_img(folder + file, target_size=(200, 200))\n",
    "# \t# convert to numpy array\n",
    "# \tphoto = img_to_array(photo)\n",
    "# \t# store\n",
    "# \tphotos.append(photo)\n",
    "# \tlabels.append(output)\n",
    "# # convert to a numpy arrays\n",
    "# photos = asarray(photos)\n",
    "# labels = asarray(labels)\n",
    "# print(photos.shape, labels.shape)\n",
    "# # save the reshaped photos\n",
    "# save('dogs_vs_cats_photos.npy', photos)\n",
    "# save('dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the standard directories approach instead\n",
    "# photos = load('dogs_vs_cats_photos.npy')\n",
    "# labels = load('dogs_vs_cats_labels.npy')\n",
    "# print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693dd59",
   "metadata": {},
   "source": [
    "#### Pre-Process Photos into Standard Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard directory created successfully\n",
    "# dataset_home = '../../../Large_Datasets/dataset_dogs_vs_cats/'\n",
    "# subdirs = ['train/', 'test/']\n",
    "# for subdir in subdirs:\n",
    "# \t# create label subdirectories\n",
    "# \tlabeldirs = ['dogs/', 'cats/']\n",
    "# \tfor labldir in labeldirs:\n",
    "# \t\tnewdir = dataset_home + subdir + labldir\n",
    "# \t\tmakedirs(newdir, exist_ok=True)\n",
    "# # seed random number generator\n",
    "# seed(1)\n",
    "# # define ratio of pictures to use for validation\n",
    "# val_ratio = 0.25\n",
    "# # copy training dataset images into subdirectories\n",
    "# # src_directory = 'train/'\n",
    "# src_directory = '../../../Large_Datasets/cat_dog_train'\n",
    "# for file in listdir(src_directory):\n",
    "# \tsrc = src_directory + '/' + file\n",
    "# \tdst_dir = 'train/'\n",
    "# \tif random() < val_ratio:\n",
    "# \t\tdst_dir = 'test/'\n",
    "# \tif file.startswith('cat'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
    "# \t\tcopyfile(src, dst)\n",
    "# \telif file.startswith('dog'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "# \t\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2774f3b",
   "metadata": {},
   "source": [
    "#### Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "357f8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa218c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335f3692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de42ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## able to utilize GPU\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f37df5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18697 images belonging to 2 classes.\n",
      "Found 6303 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "  2/293 [..............................] - ETA: 15s - loss: 1.4475 - accuracy: 0.5234WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0379s vs `on_train_batch_end` time: 0.0671s). Check your callbacks.\n",
      "293/293 [==============================] - 98s 333ms/step - loss: 0.7308 - accuracy: 0.5466 - val_loss: 0.6781 - val_accuracy: 0.5851\n",
      "Epoch 2/20\n",
      "293/293 [==============================] - 94s 319ms/step - loss: 0.6715 - accuracy: 0.5845 - val_loss: 0.6899 - val_accuracy: 0.5524\n",
      "Epoch 3/20\n",
      "293/293 [==============================] - 92s 316ms/step - loss: 0.6576 - accuracy: 0.6121 - val_loss: 0.6487 - val_accuracy: 0.6173\n",
      "Epoch 4/20\n",
      "293/293 [==============================] - 92s 315ms/step - loss: 0.6449 - accuracy: 0.6203 - val_loss: 0.6454 - val_accuracy: 0.6221\n",
      "Epoch 5/20\n",
      "293/293 [==============================] - 92s 315ms/step - loss: 0.6361 - accuracy: 0.6265 - val_loss: 0.6327 - val_accuracy: 0.6324\n",
      "Epoch 6/20\n",
      "293/293 [==============================] - 90s 307ms/step - loss: 0.6236 - accuracy: 0.6391 - val_loss: 0.6566 - val_accuracy: 0.5875\n",
      "Epoch 7/20\n",
      "293/293 [==============================] - 93s 316ms/step - loss: 0.6141 - accuracy: 0.6528 - val_loss: 0.6145 - val_accuracy: 0.6495\n",
      "Epoch 8/20\n",
      "293/293 [==============================] - 93s 318ms/step - loss: 0.6014 - accuracy: 0.6673 - val_loss: 0.6190 - val_accuracy: 0.6597\n",
      "Epoch 9/20\n",
      "293/293 [==============================] - 93s 319ms/step - loss: 0.5878 - accuracy: 0.6814 - val_loss: 0.5956 - val_accuracy: 0.6637\n",
      "Epoch 10/20\n",
      "293/293 [==============================] - 94s 321ms/step - loss: 0.5802 - accuracy: 0.6935 - val_loss: 0.6470 - val_accuracy: 0.6156\n",
      "Epoch 11/20\n",
      "293/293 [==============================] - 93s 318ms/step - loss: 0.5611 - accuracy: 0.7079 - val_loss: 0.6100 - val_accuracy: 0.6679\n",
      "Epoch 12/20\n",
      "293/293 [==============================] - 92s 315ms/step - loss: 0.5409 - accuracy: 0.7244 - val_loss: 0.5864 - val_accuracy: 0.6838\n",
      "Epoch 13/20\n",
      "293/293 [==============================] - 92s 313ms/step - loss: 0.5237 - accuracy: 0.7370 - val_loss: 0.5798 - val_accuracy: 0.6925\n",
      "Epoch 14/20\n",
      "293/293 [==============================] - 93s 317ms/step - loss: 0.5060 - accuracy: 0.7521 - val_loss: 0.5723 - val_accuracy: 0.6944\n",
      "Epoch 15/20\n",
      "293/293 [==============================] - 92s 315ms/step - loss: 0.4781 - accuracy: 0.7722 - val_loss: 0.5499 - val_accuracy: 0.7203\n",
      "Epoch 16/20\n",
      "293/293 [==============================] - 92s 313ms/step - loss: 0.4510 - accuracy: 0.7880 - val_loss: 0.5475 - val_accuracy: 0.7230\n",
      "Epoch 17/20\n",
      "293/293 [==============================] - 91s 310ms/step - loss: 0.4236 - accuracy: 0.8076 - val_loss: 0.5365 - val_accuracy: 0.7330\n",
      "Epoch 18/20\n",
      "293/293 [==============================] - 91s 310ms/step - loss: 0.3895 - accuracy: 0.8261 - val_loss: 0.5538 - val_accuracy: 0.7219\n",
      "Epoch 19/20\n",
      "293/293 [==============================] - 92s 314ms/step - loss: 0.3542 - accuracy: 0.8499 - val_loss: 0.5414 - val_accuracy: 0.7349\n",
      "Epoch 20/20\n",
      "293/293 [==============================] - 93s 318ms/step - loss: 0.3252 - accuracy: 0.8651 - val_loss: 0.5416 - val_accuracy: 0.7431\n",
      "WARNING:tensorflow:From C:\\Users\\liamk\\AppData\\Local\\Temp\\ipykernel_15844\\2204847392.py:46: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "> 74.314\n"
     ]
    }
   ],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterators\n",
    "    train_it = datagen.flow_from_directory('../../../Large_Datasets/dataset_dogs_vs_cats/train/',\n",
    "        class_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "    test_it = datagen.flow_from_directory('../../../Large_Datasets/dataset_dogs_vs_cats/test/',\n",
    "        class_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "    # fit model\n",
    "    history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    "    \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d750d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
