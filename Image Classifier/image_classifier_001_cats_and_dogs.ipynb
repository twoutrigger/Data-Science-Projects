{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20323905",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic image classification algo using CNN\n",
    "## tutorial url\n",
    "## https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6277458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.utils import load_img # moved from .preprocessing.image\n",
    "from keras.utils import img_to_array # moved from .preprocessing.image\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define location of dataset\n",
    "folder = '../../../Large_Datasets/cat_dog_train/'\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# define filename\n",
    "\tfilename = folder + 'dog.' + str(i) + '.jpg'\n",
    "\t# load image pixels\n",
    "\timage = imread(filename)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092ab92",
   "metadata": {},
   "source": [
    "#### Pre-process image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the standard directories approach instead\n",
    "# folder = '../../../Large_Datasets/cat_dog_train/'\n",
    "# photos, labels = list(), list()\n",
    "# # enumerate files in the directory\n",
    "# for file in listdir(folder):\n",
    "# \t# determine class\n",
    "# \toutput = 0.0\n",
    "# \tif file.startswith('dog'):\n",
    "# \t\toutput = 1.0\n",
    "# \t# load image\n",
    "# \tphoto = load_img(folder + file, target_size=(200, 200))\n",
    "# \t# convert to numpy array\n",
    "# \tphoto = img_to_array(photo)\n",
    "# \t# store\n",
    "# \tphotos.append(photo)\n",
    "# \tlabels.append(output)\n",
    "# # convert to a numpy arrays\n",
    "# photos = asarray(photos)\n",
    "# labels = asarray(labels)\n",
    "# print(photos.shape, labels.shape)\n",
    "# # save the reshaped photos\n",
    "# save('dogs_vs_cats_photos.npy', photos)\n",
    "# save('dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the standard directories approach instead\n",
    "# photos = load('dogs_vs_cats_photos.npy')\n",
    "# labels = load('dogs_vs_cats_labels.npy')\n",
    "# print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693dd59",
   "metadata": {},
   "source": [
    "#### Pre-Process Photos into Standard Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard directory created successfully\n",
    "# dataset_home = '../../../Large_Datasets/dataset_dogs_vs_cats/'\n",
    "# subdirs = ['train/', 'test/']\n",
    "# for subdir in subdirs:\n",
    "# \t# create label subdirectories\n",
    "# \tlabeldirs = ['dogs/', 'cats/']\n",
    "# \tfor labldir in labeldirs:\n",
    "# \t\tnewdir = dataset_home + subdir + labldir\n",
    "# \t\tmakedirs(newdir, exist_ok=True)\n",
    "# # seed random number generator\n",
    "# seed(1)\n",
    "# # define ratio of pictures to use for validation\n",
    "# val_ratio = 0.25\n",
    "# # copy training dataset images into subdirectories\n",
    "# # src_directory = 'train/'\n",
    "# src_directory = '../../../Large_Datasets/cat_dog_train'\n",
    "# for file in listdir(src_directory):\n",
    "# \tsrc = src_directory + '/' + file\n",
    "# \tdst_dir = 'train/'\n",
    "# \tif random() < val_ratio:\n",
    "# \t\tdst_dir = 'test/'\n",
    "# \tif file.startswith('cat'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
    "# \t\tcopyfile(src, dst)\n",
    "# \telif file.startswith('dog'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "# \t\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2774f3b",
   "metadata": {},
   "source": [
    "#### Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab952861",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## switching over to tensorflow on GPU to improve speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('../../../Large_Datasets/dataset_dogs_vs_cats/train/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('../../../Large_Datasets/dataset_dogs_vs_cats/test/',\n",
    "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8d4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
