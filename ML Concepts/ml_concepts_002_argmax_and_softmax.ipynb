{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## better understanding of argmax and softmax, common components in neural networks\n",
    "## tutorial url:\n",
    "## https://machinelearningmastery.com/softmax-activation-function-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "Softmax is a mathematical function that converts a vector of numbers into a vector of probabilities, where the probabilities of each value are proportional to the relative scale of each value in the vector.\n",
    "\n",
    "The most common use of the softmax function in applied machine learning is in its use as an activation function in a neural network model. Specifically, the network is configured to output N values, one for each class in the classification task, and the softmax function is used to normalize the outputs, converting them from weighted sum values into probabilities that sum to one. Each value in the output of the softmax function is interpreted as the probability of membership for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a binary classification problem, a Binomial probability distribution is used. This is achieved using a network with a single node in the output layer that predicts the probability of an example belonging to class 1.\n",
    "\n",
    "For a multi-class classification problem, a Multinomial probability is used. This is achieved using a network with one node for each class in the output layer and the sum of the predicted probabilities equals one.\n",
    "\n",
    "A neural network model requires an activation function in the output layer of the model to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions include:\n",
    "<br>\n",
    "Linear - inappropriate for either the binomial or multinomial case.\n",
    "<br>\n",
    "Sigmoid - aka logistic function; good for binomial, not for multi-class.\n",
    "<br>\n",
    "Argmax - returns the index in the list that contains the largest value.\n",
    "<br>\n",
    "Softmax - can be thought to be a probabilistic or “softer” version of the argmax function. It can be achieved by calculating the exponent of each value in the list and dividing it by the sum of the exponent values.\n",
    "<br>\n",
    "Softmax - \"Any time we wish to represent a probability distribution over a discrete variable with n possible values, we may use the softmax function. This can be seen as a generalization of the sigmoid function which was used to represent a probability distribution over a binary variable.\"\n",
    "<br>\n",
    "Softmax equation - probability = exp(value) / sum v in list exp(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from math import exp\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = [10, 30, 20]\n",
    "# calculate the argmax of the list\n",
    "result = argmax(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.061060046209062e-09 0.9999546000703311 4.539786860886666e-05\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# calculate each probability\n",
    "p1 = exp(10) / (exp(10) + exp(30) + exp(20))\n",
    "p2 = exp(30) / (exp(10) + exp(30) + exp(20))\n",
    "p3 = exp(20) / (exp(10) + exp(30) + exp(20))\n",
    "# report probabilities\n",
    "print(p1, p2, p3)\n",
    "# report sum of probabilities\n",
    "print(p1 + p2 + p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.06106005e-09 9.99954600e-01 4.53978686e-05]\n",
      "0.9999999999999987\n"
     ]
    }
   ],
   "source": [
    "# define data\n",
    "data = [10, 30, 20]\n",
    "# calculate softmax\n",
    "result = softmax(data)\n",
    "# report the probabilities\n",
    "print(result)\n",
    "# report the sum of the probabilities\n",
    "print(sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
