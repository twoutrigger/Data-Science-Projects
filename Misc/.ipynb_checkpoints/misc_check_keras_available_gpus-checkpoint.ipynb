{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d598dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to check if keras tensorflow backend is GPU or CPU version?\n",
    "## thread url:\n",
    "## https://stackoverflow.com/questions/45068243/how-to-check-if-keras-tensorflow-backend-is-gpu-or-cpu-version\n",
    "## https://stackoverflow.com/questions/45662253/can-i-run-keras-model-on-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4570a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4657774067782781427\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6565357808055607062\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3644309768756231679\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c2289f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "K._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a12aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1157832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\liamk\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ea97c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 12:38:08.536462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\n",
      "2022-06-01 12:38:11.637084: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\n",
      "2022-06-01 12:38:12.196928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1\n",
      "coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-06-01 12:38:12.196957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\n",
      "2022-06-01 12:38:12.201792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\n",
      "2022-06-01 12:38:12.205340: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\n",
      "2022-06-01 12:38:12.206376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\n",
      "2022-06-01 12:38:12.210010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\n",
      "2022-06-01 12:38:12.212097: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\n",
      "2022-06-01 12:38:12.214423: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found\n",
      "2022-06-01 12:38:12.214438: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tensorflow as tf;print('GPUs Available:', tf.config.list_physical_devices('GPU'))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8e1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import keras \n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b44a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tensorflow GPU install url:\n",
    "## https://www.tensorflow.org/install/pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f048baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem and solution:\n",
    "## downgrade cudatoolkit to cudatoolkit 10.1 as version is compatible with TF\n",
    "## downgrade cudnn to 8.0.5 as is compatible cudatoolkit 10.1\n",
    "## command: conda install -c conda-forge cudatoolkit=10.1 cudnn=8.0.5\n",
    "## installed tensorflow-gpu==2.3\n",
    "## coomand: pip install tensorflow-gpu==2.3 --user\n",
    "## url: https://stackoverflow.com/questions/71279211/internalerror-cudagetdevice-failed-status-initialization-error-when-running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9224de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## snippet to check directly in cmd\n",
    "## python -c \"from tensorflow.python.client import device_lib; print(device_lib.list_local_devices())\"\n",
    "## python -c \"from tensorflow.python.keras import backend; print(backend._get_available_gpus())\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
