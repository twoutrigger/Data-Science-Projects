{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook:\n",
    "# I practice determining movie sentiment with NLP\n",
    "# AKA predict if a movie comment is positve / negative\n",
    "# I clean and pre-process text for ML\n",
    "# I conduct TFIDF and count vectorization\n",
    "# I conduct logistic regression and Naive Bayes algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand column width for readability\n",
    "pd.set_option('display.max_colwidth', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId  \\\n",
       "0         1           1   \n",
       "1         2           1   \n",
       "2         3           1   \n",
       "3         4           1   \n",
       "4         5           1   \n",
       "\n",
       "                                                                  Phrase  \\\n",
       "0  A series of escapades demonstrating the adage that what is good fo...   \n",
       "1  A series of escapades demonstrating the adage that what is good fo...   \n",
       "2                                                               A series   \n",
       "3                                                                      A   \n",
       "4                                                                 series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morig = pd.read_csv('train.tsv',sep='\\t')\n",
    "\n",
    "morig.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      "PhraseId      156060 non-null int64\n",
      "SentenceId    156060 non-null int64\n",
      "Phrase        156060 non-null object\n",
      "Sentiment     156060 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "morig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(morig['SentenceId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8529, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining independent is worth s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspect , would have a ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnography and all the intr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulative whitewash .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId  \\\n",
       "0           1           1   \n",
       "63         64           2   \n",
       "81         82           3   \n",
       "116       117           4   \n",
       "156       157           5   \n",
       "\n",
       "                                                                    Phrase  \\\n",
       "0    A series of escapades demonstrating the adage that what is good fo...   \n",
       "63   This quiet , introspective and entertaining independent is worth s...   \n",
       "81   Even fans of Ismail Merchant 's work , I suspect , would have a ha...   \n",
       "116  A positively thrilling combination of ethnography and all the intr...   \n",
       "156           Aggressive self-glorification and a manipulative whitewash .   \n",
       "\n",
       "     Sentiment  \n",
       "0            1  \n",
       "63           4  \n",
       "81           1  \n",
       "116          3  \n",
       "156          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bulk of rows are n-grams; remove due to later vectorization \n",
    "morig.drop_duplicates(['SentenceId'], inplace=True)\n",
    "\n",
    "print(morig.shape)\n",
    "\n",
    "morig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morig['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up phrase text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining independent is worth s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspect , would have a ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnography and all the intr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulative whitewash .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId  \\\n",
       "0           1           1   \n",
       "63         64           2   \n",
       "81         82           3   \n",
       "116       117           4   \n",
       "156       157           5   \n",
       "\n",
       "                                                                    Phrase  \\\n",
       "0    A series of escapades demonstrating the adage that what is good fo...   \n",
       "63   This quiet , introspective and entertaining independent is worth s...   \n",
       "81   Even fans of Ismail Merchant 's work , I suspect , would have a ha...   \n",
       "116  A positively thrilling combination of ethnography and all the intr...   \n",
       "156           Aggressive self-glorification and a manipulative whitewash .   \n",
       "\n",
       "     Sentiment  \n",
       "0            1  \n",
       "63           4  \n",
       "81           1  \n",
       "116          3  \n",
       "156          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medit = morig.copy()\n",
    "\n",
    "medit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to lowercase, remove low occurance words, stop words, and perform lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2321\n",
       "1    2200\n",
       "2    1655\n",
       "4    1281\n",
       "0    1072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upon review, 4 looks to be best (liked), 0 looks to be worst (disliked)\n",
    "\n",
    "medit['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      a series of escapades demonstrating the adage that what is good fo...\n",
       "63     this quiet , introspective and entertaining independent is worth s...\n",
       "81     even fans of ismail merchant 's work , i suspect , would have a ha...\n",
       "116    a positively thrilling combination of ethnography and all the intr...\n",
       "156             aggressive self-glorification and a manipulative whitewash .\n",
       "166    a comedy-drama of nearly epic proportions rooted in a sincere perf...\n",
       "198                     narratively , trouble every day is a plodding mess .\n",
       "213    the importance of being earnest , so thick with wit it plays like ...\n",
       "247                                    but it does n't leave you with much .\n",
       "259                                  you could hate it for the same reason .\n",
       "Name: Clean, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medit['Clean'] = medit['Phrase'].apply(lambda x:\n",
    "                                       \" \".join(x.lower()\n",
    "                                       for x in str(x).split()))\n",
    "medit['Clean'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      a series of escapades demonstrating the adage that what is good fo...\n",
       "63     this quiet   introspective and entertaining independent is worth s...\n",
       "81     even fans of ismail merchant  s work   i suspect   would have a ha...\n",
       "116    a positively thrilling combination of ethnography and all the intr...\n",
       "156             aggressive self glorification and a manipulative whitewash  \n",
       "166    a comedy drama of nearly epic proportions rooted in a sincere perf...\n",
       "198                     narratively   trouble every day is a plodding mess  \n",
       "213    the importance of being earnest   so thick with wit it plays like ...\n",
       "247                                    but it does n t leave you with much  \n",
       "259                                  you could hate it for the same reason  \n",
       "Name: Clean, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medit['Clean'] = medit['Clean'].str.replace('[^\\w\\s]', ' ')\n",
    "\n",
    "medit['Clean'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      series escapades demonstrating adage good goose also good gander o...\n",
       "63                quiet introspective entertaining independent worth seeking\n",
       "81        even fans ismail merchant work suspect would hard time sitting one\n",
       "116    positively thrilling combination ethnography intrigue betrayal dec...\n",
       "156                     aggressive self glorification manipulative whitewash\n",
       "166    comedy drama nearly epic proportions rooted sincere performance ti...\n",
       "198                              narratively trouble every day plodding mess\n",
       "213    importance earnest thick wit plays like reading bartlett familiar ...\n",
       "247                                                             n leave much\n",
       "259                                                        could hate reason\n",
       "Name: Clean, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "medit['Clean'] = medit['Clean'].apply(lambda x:\n",
    "                                      \" \".join(x for x in str(x).split()\n",
    "                                      if x not in stop))\n",
    "\n",
    "medit['Clean'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      series escapades demonstrate adage good goose also good gander occ...\n",
       "63                      quiet introspective entertain independent worth seek\n",
       "81             even fan ismail merchant work suspect would hard time sit one\n",
       "116    positively thrill combination ethnography intrigue betrayal deceit...\n",
       "156                     aggressive self glorification manipulative whitewash\n",
       "166    comedy drama nearly epic proportion root sincere performance title...\n",
       "198                                  narratively trouble every day plod mess\n",
       "213    importance earnest thick wit play like read bartlett familiar quot...\n",
       "247                                                             n leave much\n",
       "259                                                        could hate reason\n",
       "Name: Clean, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medit['Clean'] = medit['Clean'].apply(lambda x:\n",
    "                                      \" \".join([Word(word).lemmatize(pos='v')\n",
    "                                      for word in x.split()]))\n",
    "\n",
    "medit['Clean'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film         1294\n",
       "movie        1008\n",
       "n             687\n",
       "make          609\n",
       "one           576\n",
       "like          527\n",
       "rrb           352\n",
       "lrb           351\n",
       "story         350\n",
       "character     348\n",
       "time          330\n",
       "good          294\n",
       "work          289\n",
       "even          265\n",
       "much          264\n",
       "comedy        264\n",
       "feel          259\n",
       "see           249\n",
       "get           241\n",
       "well          236\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_phrase = pd.Series(' '.join(medit['Clean']).split()).value_counts()\n",
    "\n",
    "freq_phrase[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current phrase count is: 12486\n",
      "Rare phrase count is: 7513\n"
     ]
    }
   ],
   "source": [
    "print(f'Current phrase count is: {len(freq_phrase)}')\n",
    "\n",
    "rare_phrase = freq_phrase[(freq_phrase == 1) | (freq_phrase == 2)]\n",
    "\n",
    "print(f'Rare phrase count is: {len(rare_phrase)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      series demonstrate adage good goose also good occasionally amuse n...\n",
       "63                      quiet introspective entertain independent worth seek\n",
       "81                    even fan merchant work suspect would hard time sit one\n",
       "116    positively thrill combination intrigue betrayal murder shakespeare...\n",
       "156                                             aggressive self manipulative\n",
       "166    comedy drama nearly epic proportion root sincere performance title...\n",
       "198                                  narratively trouble every day plod mess\n",
       "213            importance earnest thick wit play like read bartlett familiar\n",
       "247                                                             n leave much\n",
       "259                                                        could hate reason\n",
       "Name: Clean, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medit['Clean'] = medit['Clean'].apply(lambda x:\n",
    "                                      \" \".join(x for x in str(x).split()\n",
    "                                      if x not in rare_phrase))\n",
    "\n",
    "medit['Clean'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8529x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 40911 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    "                        stop_words = 'english', ngram_range=(1,1))\n",
    "\n",
    "tfvec = tfv.fit_transform(medit['Clean'])\n",
    "\n",
    "tfvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'series': 762,\n",
       " 'demonstrate': 210,\n",
       " 'good': 373,\n",
       " 'occasionally': 588,\n",
       " 'amuse': 32,\n",
       " 'story': 832,\n",
       " 'quiet': 679,\n",
       " 'entertain': 268,\n",
       " 'worth': 988,\n",
       " 'seek': 754,\n",
       " 'fan': 302,\n",
       " 'work': 984,\n",
       " 'hard': 394,\n",
       " 'time': 893,\n",
       " 'sit': 785,\n",
       " 'thrill': 890,\n",
       " 'intrigue': 459,\n",
       " 'murder': 570,\n",
       " 'tragedy': 900,\n",
       " 'soap': 796}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brief look at the transfomed vocab with feature indices\n",
    "\n",
    "first20vocab = {x: tfv.vocabulary_[x] for x in list(tfv.vocabulary_)[:20]}\n",
    "\n",
    "first20vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10': 7.106905661319284,\n",
       " '20': 7.343294439383515,\n",
       " '2002': 7.16097288258956,\n",
       " '90': 6.793248102464243,\n",
       " 'ability': 7.106905661319284,\n",
       " 'able': 6.832468815617524,\n",
       " 'absolutely': 7.16097288258956,\n",
       " 'absorb': 7.006822202762302,\n",
       " 'accomplish': 7.343294439383515,\n",
       " 'achieve': 7.106905661319284,\n",
       " 'act': 5.047398334540266,\n",
       " 'action': 5.07461089806515,\n",
       " 'actor': 6.524984115869564,\n",
       " 'actors': 5.733856526949414,\n",
       " 'actress': 7.055612366931734,\n",
       " 'actually': 6.0259929497505755,\n",
       " 'adaptation': 6.9158504245565755,\n",
       " 'add': 6.495996578996311,\n",
       " 'adults': 6.873290810137779,\n",
       " 'adventure': 6.387782994356078}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brief look at the transformed vocab with IDF values\n",
    "\n",
    "first20idf = {x: dict(zip(tfv.get_feature_names(), tfv.idf_))[x] for x in \n",
    "              list(dict(zip(tfv.get_feature_names(), tfv.idf_)))[:20]}\n",
    "\n",
    "first20idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8529x4947 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 71005 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "cvec = cv.fit_transform(medit['Clean'])\n",
    "\n",
    "cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'series': 3864,\n",
       " 'demonstrate': 1140,\n",
       " 'adage': 83,\n",
       " 'good': 1895,\n",
       " 'goose': 1902,\n",
       " 'also': 165,\n",
       " 'occasionally': 3020,\n",
       " 'amuse': 191,\n",
       " 'none': 2973,\n",
       " 'amount': 190,\n",
       " 'much': 2865,\n",
       " 'story': 4196,\n",
       " 'quiet': 3461,\n",
       " 'introspective': 2324,\n",
       " 'entertain': 1458,\n",
       " 'independent': 2221,\n",
       " 'worth': 4904,\n",
       " 'seek': 3833,\n",
       " 'even': 1502,\n",
       " 'fan': 1621}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brief look at the transfomed vocab for count vectorizer\n",
    "\n",
    "first20cvocab = {x: cv.vocabulary_[x] for x in list(cv.vocabulary_)[:20]}\n",
    "\n",
    "first20cvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx_train: (6396, 1000)\n",
      "ty_train: (6396,)\n",
      "tx_test: (2133, 1000)\n",
      "ty_test: (2133,)\n"
     ]
    }
   ],
   "source": [
    "(tx_train, tx_test, ty_train, ty_test) = train_test_split(tfvec,medit['Sentiment'], test_size=0.25)\n",
    "\n",
    "print(f'tx_train: {tx_train.shape}\\nty_train: {ty_train.shape}')\n",
    "print(f'tx_test: {tx_test.shape}\\nty_test: {ty_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cx_train: (6396, 4947)\n",
      "cy_train: (6396,)\n",
      "cx_test: (2133, 4947)\n",
      "cy_test: (2133,)\n"
     ]
    }
   ],
   "source": [
    "(cx_train, cx_test, cy_train, cy_test) = train_test_split(cvec,medit['Sentiment'], test_size=0.25)\n",
    "\n",
    "print(f'cx_train: {cx_train.shape}\\ncy_train: {cy_train.shape}')\n",
    "print(f'cx_test: {cx_test.shape}\\ncy_test: {cy_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Vectorization Accuracy: C=0.01 0.2873886544772621\n",
      "TFIDF Vectorization Accuracy: C=0.05 0.33567744960150026\n",
      "TFIDF Vectorization Accuracy: C=0.25 0.34458509142053445\n",
      "TFIDF Vectorization Accuracy: C=0.5 0.3534927332395687\n",
      "TFIDF Vectorization Accuracy: C=1 0.35114861697140176\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    tlreg = LogisticRegression(C=c)\n",
    "    tlreg.fit(tx_train, ty_train)\n",
    "    print (f'TFIDF Vectorization Accuracy: C={c} {accuracy_score(ty_test, tlreg.predict(tx_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorization Accuracy: C=0.01 0.3488045007032349\n",
      "Count Vectorization Accuracy: C=0.05 0.36146272855133615\n",
      "Count Vectorization Accuracy: C=0.25 0.37787154242850446\n",
      "Count Vectorization Accuracy: C=0.5 0.3722456633849039\n",
      "Count Vectorization Accuracy: C=1 0.3628691983122363\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    clreg = LogisticRegression(C=c)\n",
    "    clreg.fit(cx_train, cy_train)\n",
    "    print (f'Count Vectorization Accuracy: C={c} {accuracy_score(cy_test, clreg.predict(cx_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.36099390529770276\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes model\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnbmodel = mnb.fit(tx_train, ty_train)\n",
    "\n",
    "print (f'Naive Bayes Accuracy: {accuracy_score(ty_test, mnbmodel.predict(tx_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = ['it was a pretty good movie', 'the flick is mediocre', 'Jake was terrible in the second act',\n",
    "               'Life Itself is full of cliche, but fits a certain artsy crowd', 'will watch again!',\n",
    "               'Entertaining movie, shallow story, good action, I would rate 4 out of 5', 'damn good movie!']\n",
    "\n",
    "test_c_vec = cv.transform(test_phrase)\n",
    "# test_c_vec yields type mismatch with ML algos; will reinvestigate\n",
    "\n",
    "test_t_vec = tfv.transform(test_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes prediction: 3   Phrase: it was a pretty good movie\n",
      "Naive Bayes prediction: 1   Phrase: the flick is mediocre\n",
      "Naive Bayes prediction: 0   Phrase: Jake was terrible in the second act\n",
      "Naive Bayes prediction: 2   Phrase: Life Itself is full of cliche, but fits a certain artsy crowd\n",
      "Naive Bayes prediction: 3   Phrase: will watch again!\n",
      "Naive Bayes prediction: 1   Phrase: Entertaining movie, shallow story, good action, I would rate 4 out of 5\n",
      "Naive Bayes prediction: 3   Phrase: damn good movie!\n"
     ]
    }
   ],
   "source": [
    "test_mnb_pred = mnbmodel.predict(test_t_vec)\n",
    "\n",
    "for name, pred in zip(test_phrase, test_mnb_pred):\n",
    "    print(f'Naive Bayes prediction: {pred}   Phrase: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression prediction: 3   Phrase: it was a pretty good movie\n",
      "Logistic regression prediction: 1   Phrase: the flick is mediocre\n",
      "Logistic regression prediction: 0   Phrase: Jake was terrible in the second act\n",
      "Logistic regression prediction: 2   Phrase: Life Itself is full of cliche, but fits a certain artsy crowd\n",
      "Logistic regression prediction: 0   Phrase: will watch again!\n",
      "Logistic regression prediction: 1   Phrase: Entertaining movie, shallow story, good action, I would rate 4 out of 5\n",
      "Logistic regression prediction: 3   Phrase: damn good movie!\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1)\n",
    "logmodel = logreg.fit(tx_train, ty_train)\n",
    "\n",
    "test_log_pred = logmodel.predict(test_t_vec)\n",
    "\n",
    "for name, pred in zip(test_phrase, test_log_pred):\n",
    "    print(f'Logistic regression prediction: {pred}   Phrase: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing thoughts for pt 1:\n",
    "# we see pretty good predictions with TFIDF vectorization + ML\n",
    "# however overall acuuracy can be imporved\n",
    "# this will likely require better preprocessing, or ensamble algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
