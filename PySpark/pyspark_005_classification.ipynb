{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d55e715",
   "metadata": {},
   "source": [
    "## Purpose of script:\n",
    "#### Basic tutorial on doing classification with PySpark ML\n",
    "#### Code references:\n",
    "#### https://pub.towardsai.net/pyspark-mllib-classification-using-pyspark-ml-ec7e99e5176f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf6c0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\liamk\\\\Documents\\\\spark\\\\spark-3.3.1-bin-hadoop3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "933ad0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc6514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('classification').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f086362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-----+-------+--------+------+--------+\n",
      "|buying|maintainence|doors|persons|lug_boot|safety|car_type|\n",
      "+------+------------+-----+-------+--------+------+--------+\n",
      "| vhigh|       vhigh|    2|      2|   small|   low|   unacc|\n",
      "| vhigh|       vhigh|    2|      2|   small|   med|   unacc|\n",
      "| vhigh|       vhigh|    2|      2|   small|  high|   unacc|\n",
      "| vhigh|       vhigh|    2|      2|     med|   low|   unacc|\n",
      "| vhigh|       vhigh|    2|      2|     med|   med|   unacc|\n",
      "+------+------------+-----+-------+--------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"../Datasets/car_data.csv\",inferSchema=True, header=True)\n",
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf70980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- buying: string (nullable = true)\n",
      " |-- maintainence: string (nullable = true)\n",
      " |-- doors: string (nullable = true)\n",
      " |-- persons: string (nullable = true)\n",
      " |-- lug_boot: string (nullable = true)\n",
      " |-- safety: string (nullable = true)\n",
      " |-- car_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7883b303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+\n",
      "|buying_encoded|doors_encoded|maintainence_encoded|persons_encoded|lug_boot_encoded|safety_encoded|car_type_encoded|\n",
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+\n",
      "|             3|            0|                   3|              0|               2|             1|               0|\n",
      "|             3|            0|                   3|              0|               2|             2|               0|\n",
      "|             3|            0|                   3|              0|               2|             0|               0|\n",
      "|             3|            0|                   3|              0|               1|             1|               0|\n",
      "|             3|            0|                   3|              0|               1|             2|               0|\n",
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Liam: revisit this in regards to one-hot encoding\n",
    "categoricalColumns = [\"buying\",\"maintainence\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"car_type\"]\n",
    "l = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol+\"_encoded\")\\\n",
    "        .fit(df_pyspark)\n",
    "    df_pyspark = stringIndexer.transform(df_pyspark)\n",
    "    df_pyspark = df_pyspark.withColumn(categoricalCol+\"_encoded\", df_pyspark[categoricalCol+\"_encoded\"]\\\n",
    "                                       .cast('int'))\n",
    "encoded_df =  df_pyspark.select(\"buying_encoded\",\"doors_encoded\",\"maintainence_encoded\",\n",
    "                                \"persons_encoded\", \"lug_boot_encoded\",\"safety_encoded\",\"car_type_encoded\")\n",
    "encoded_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4d0a811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|            features|car_type_encoded|\n",
      "+--------------------+----------------+\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureAssembler = VectorAssembler(inputCols=[\"buying_encoded\",\"doors_encoded\",\"maintainence_encoded\",\n",
    "                                              \"persons_encoded\",\"lug_boot_encoded\",\"safety_encoded\"],\n",
    "                                   outputCol=\"features\")\n",
    "\n",
    "output = featureAssembler.transform(encoded_df)\n",
    "output.select(\"features\",\"car_type_encoded\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47d40140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377 351\n"
     ]
    }
   ],
   "source": [
    "train, test = output.randomSplit([0.8, 0.2], seed=17)\n",
    "print(train.count(), test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81aad1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'car_type_encoded', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f14d3675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+--------------------+--------------------+----------+\n",
      "|car_type_encoded|           features|       rawPrediction|         probability|prediction|\n",
      "+----------------+-------------------+--------------------+--------------------+----------+\n",
      "|               0|          (6,[],[])|[1.99198136762975...|[0.76125517518711...|       0.0|\n",
      "|               0|      (6,[4],[2.0])|[3.26816128608163...|[0.90473344519298...|       0.0|\n",
      "|               1|(6,[3,5],[1.0,2.0])|[3.15138940343149...|[0.70074537804716...|       0.0|\n",
      "|               1|(6,[3,5],[2.0,2.0])|[2.05830537339739...|[0.38137779317689...|       1.0|\n",
      "|               1|(6,[3,4],[2.0,1.0])|[0.44390326678749...|[0.30253957413616...|       1.0|\n",
      "+----------------+-------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "\n",
    "predictions.select('car_type_encoded', 'features', 'rawPrediction', 'probability', 'prediction')\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21846dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Continue with evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
