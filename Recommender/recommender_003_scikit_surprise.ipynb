{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tutorial of surprise, a Python package for matrix factorization / KNN recommender\n",
    "## surprise is not for content-based recommendations\n",
    "## tutorial url:\n",
    "## https://surprise.readthedocs.io/en/stable/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
      "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\liamk/.surprise_data/ml-100k\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9361  0.9388  0.9410  0.9304  0.9331  0.9359  0.0038  \n",
      "MAE (testset)     0.7384  0.7384  0.7415  0.7322  0.7372  0.7375  0.0030  \n",
      "Fit time          5.07    5.32    5.37    5.38    5.37    5.30    0.12    \n",
      "Test time         0.17    0.19    0.16    0.14    0.14    0.16    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93610272, 0.9388455 , 0.94095554, 0.93041995, 0.93308442]),\n",
       " 'test_mae': array([0.7383522 , 0.7384209 , 0.74149551, 0.73215999, 0.73717831]),\n",
       " 'fit_time': (5.065744638442993,\n",
       "  5.320963144302368,\n",
       "  5.371641635894775,\n",
       "  5.379650592803955,\n",
       "  5.369688510894775),\n",
       " 'test_time': (0.1735367774963379,\n",
       "  0.1904909610748291,\n",
       "  0.1575772762298584,\n",
       "  0.14262080192565918,\n",
       "  0.14161372184753418)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tutorial url:\n",
    "## https://surprise.readthedocs.io/en/stable/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9402789192887656"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tutorial url:\n",
    "## https://surprise.readthedocs.io/en/stable/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x22c2e5b4be0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the trainset.\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Build an algorithm, and train it.\n",
    "algo = KNNBasic()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.06   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 100        item: 314        r_ui = 4.00   est = 1.00   {'actual_k': 5, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(100)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(314)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N Recommendations for user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "# First train an SVD algorithm on the movielens dataset.\n",
    "# data = Dataset.load_builtin('ml-100k')\n",
    "# trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "\n",
    "## returns top n items for each user\n",
    "# Print the recommended items for each user\n",
    "# for uid, user_ratings in top_n.items():\n",
    "#     print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'196': [('64', 4.769798580013519),\n",
       "  ('114', 4.6087618010957785),\n",
       "  ('318', 4.56637306569748),\n",
       "  ('408', 4.516162819041641),\n",
       "  ('357', 4.487254416788829),\n",
       "  ('479', 4.481264796988658),\n",
       "  ('169', 4.477466060096285),\n",
       "  ('515', 4.465058006971798),\n",
       "  ('98', 4.442689993258031),\n",
       "  ('657', 4.4307557881510595)],\n",
       " '186': [('313', 4.547914828124093),\n",
       "  ('513', 4.508279698704069),\n",
       "  ('531', 4.4927791433497175),\n",
       "  ('479', 4.4878758874877045),\n",
       "  ('50', 4.446428689141754),\n",
       "  ('498', 4.41514210258116),\n",
       "  ('22', 4.413821533323922),\n",
       "  ('223', 4.390087962053175),\n",
       "  ('657', 4.38899060938893),\n",
       "  ('921', 4.379178433047381)]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## filters for just the first 2 users\n",
    "dict(list(top_n.items())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get K nearest of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBaseline\n",
    "from surprise import get_dataset_dir\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "The 10 nearest neighbors of Toy Story are:\n",
      "Raiders of the Lost Ark (1981)\n",
      "Back to the Future (1985)\n",
      "Return of the Jedi (1983)\n",
      "Independence Day (ID4) (1996)\n",
      "Star Wars (1977)\n",
      "While You Were Sleeping (1995)\n",
      "Liar Liar (1997)\n",
      "Jurassic Park (1993)\n",
      "Better Off Dead... (1985)\n",
      "Maverick (1994)\n"
     ]
    }
   ],
   "source": [
    "def read_item_names():\n",
    "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
    "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "\n",
    "    return rid_to_name, name_to_rid\n",
    "\n",
    "\n",
    "# First, train the algortihm to compute the similarities between items\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# Retrieve inner id of the movie Toy Story\n",
    "toy_story_raw_id = name_to_rid['Toy Story (1995)']\n",
    "## another example\n",
    "# toy_story_raw_id = name_to_rid['Indiana Jones and the Last Crusade (1989)']\n",
    "toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n",
    "\n",
    "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n",
    "\n",
    "# Convert inner ids of the neighbors into names.\n",
    "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                       for inner_id in toy_story_neighbors)\n",
    "toy_story_neighbors = (rid_to_name[rid]\n",
    "                       for rid in toy_story_neighbors)\n",
    "\n",
    "print()\n",
    "print('The 10 nearest neighbors of Toy Story are:')\n",
    "for movie in toy_story_neighbors:\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get K nearest of users (self-attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Top 10 users most similiar to user id 100: [90, 384, 162, 105, 333, 534, 308, 377, 888, 802]\n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "print()\n",
    "print(f'Top 10 users most similiar to user id 100: {algo.get_neighbors(100, k=10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6420643336868154\n",
      "0.23974209073365432\n",
      "0.6510969568294418\n",
      "0.24136661766843756\n",
      "0.6320961470484281\n",
      "0.2430249134124122\n",
      "0.6285031847133764\n",
      "0.2295466936597985\n",
      "0.629462707670556\n",
      "0.2380865422492218\n"
     ]
    }
   ],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "\n",
    "# data = Dataset.load_builtin('ml-100k')\n",
    "kf = KFold(n_splits=5)\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    print(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
